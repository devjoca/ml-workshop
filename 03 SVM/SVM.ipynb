{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este ejercicio es aprender experimentalmente a ajustar un modelo SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de hiperparámetros para SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomado del libro 'Python Data Science Handbook' de Jake VanderPlas\n",
    "def plot_svc_decision_function(model, ax=None, plot_support=True, levels=[-1, 0, 1], linestyles=['--', '-', '--']):\n",
    "    \"\"\"Plot the decision function for a 2D SVC\"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "    \n",
    "    # create grid to evaluate model\n",
    "    x = np.linspace(xlim[0], xlim[1], 30)\n",
    "    y = np.linspace(ylim[0], ylim[1], 30)\n",
    "    Y, X = np.meshgrid(y, x)\n",
    "    xy = np.vstack([X.ravel(), Y.ravel()]).T\n",
    "    P = model.decision_function(xy).reshape(X.shape)\n",
    "    \n",
    "    # plot decision boundary and margins\n",
    "    ax.contour(X, Y, P, colors='k',\n",
    "               levels=levels, alpha=0.5,\n",
    "               linestyles=linestyles)\n",
    "    \n",
    "    # plot support vectors\n",
    "    if plot_support:\n",
    "        ax.scatter(model.support_vectors_[:, 0],\n",
    "                   model.support_vectors_[:, 1],\n",
    "                   s=300, linewidth=1, facecolors='none');\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccionar los parámetros $C$ y $\\gamma$ requeridos por el kernel gaussiano.\n",
    "\n",
    "La selección de los modelos de un parámetro se realiza por medio de *cross validation*. Para ello se reserva una muestra aleatoria del conjunto de datos que pueda servir para estimar el grado de generalización de los modelos a evaluar.\n",
    "\n",
    "Para este caso recibimos directamente el conjunto de entrenamiento `(X, y)` y el conjunto de validación `(Xval, yval)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataP2_train = pd.read_csv('svmdatatrain.csv', names=['x1', 'x2', 'y'])\n",
    "X = dataP2_train[['x1', 'x2']]\n",
    "y = dataP2_train['y']\n",
    "\n",
    "dataP2_val = pd.read_csv('svmdataval.csv', names=['x1', 'x2', 'y'])\n",
    "Xval = dataP2_val[['x1', 'x2']]\n",
    "yval = dataP2_val['y']\n",
    "\n",
    "plt.title('Conjunto de datos Pregunta 2')\n",
    "plt.margins(x=0, y=0)\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.scatter(X['x1'], X['x2'], c=y, s=10, cmap='prism', label='Conjunto de entrenamiento')\n",
    "plt.scatter(Xval['x1'], Xval['x2'], c=yval, marker='x', s=20, cmap='prism', label='Conjunto de validacion')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizaremos también la normalización de los datos. Presta atención a que la normalización de los datos de validación $X_{val}$ se debe realizar con los parámetros obtenidos del conjunto de entrenamiento $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "Xval_scaled = scaler.transform(Xval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparemos la exactitud en los conjuntos de entrenamiento y validación para un modelo con $C=200$ y $\\gamma = 50$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel='rbf', C=200, gamma=50)\n",
    "model.fit(X_scaled, y)\n",
    "\n",
    "score_train = model.score(X_scaled, y)\n",
    "score_val = model.score(Xval_scaled, yval)\n",
    "\n",
    "print ('Exactitud en el conjunto de entrenamiento: %0.4f' % score_train)\n",
    "print ('Exactitud en el conjunto de validación: %0.4f' % score_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si bien se tiene una exactitud muy alta en el conjunto de entrenamiento, la exactitud es bastante menor en el conjunto de validación. Este es un síntoma claro de sobreajuste *(overfitting)*. Visualicemos lo que está ocurriendo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización\n",
    "plt.title('SVM con kernel gaussiano (C=200, gamma=50) (Conjunto de datos 3 normalizado)')\n",
    "plt.margins(x=0, y=0)\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.scatter(X_scaled[:,0], X_scaled[:,1], c=y, s=10, cmap='prism', label='Conjunto de entrenamiento')\n",
    "plt.scatter(Xval_scaled[:,0], Xval_scaled[:,1], c=yval, marker='x', s=20, cmap='prism', label='Conjunto de validacion')\n",
    "plot_svc_decision_function(model, plot_support=False, levels=[0], linestyles=['-']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos apreciar visualmente que la generalización es deficiente porque el modelo está *\"memorizando\"* la ubicación de los valores atípicos. Este no es un comportamiento deseable.\n",
    "\n",
    "Para determinar valores $C$ y $\\gamma$ que brinden una mejor generalización, es necesario probar con diferentes valores, ajustando el modelo en el conjunto de entrenamiento y probando su desempeño en el conjunto de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = np.logspace(-2,2,9)  # ~ [0.01, 0.03, 0.1, ..., 100]\n",
    "gammas = np.logspace(-4,4,9)  # [0.0001, 0.001, ..., 10000]\n",
    "\n",
    "mejor_modelo = None\n",
    "mejor_score = 0\n",
    "for C in Cs:\n",
    "    for gamma in gammas:\n",
    "        \n",
    "        model = SVC(kernel='rbf', C=C, gamma=gamma)\n",
    "        model.fit(X_scaled, y)\n",
    "        \n",
    "        score_val = model.score(Xval_scaled, yval)\n",
    "        \n",
    "        if score_val > mejor_score:\n",
    "            mejor_score = score_val\n",
    "            mejor_modelo = model\n",
    "\n",
    "print ('Mejor valor de C: %0.4f' % mejor_modelo.get_params()['C'])\n",
    "print ('Mejor valor de gamma: %0.4f' % mejor_modelo.get_params()['gamma'])\n",
    "print ('Exactitud en el conjunto de entrenamiento: %0.4f' % mejor_modelo.score(X_scaled, y))\n",
    "print ('Exactitud en el conjunto de validación: %0.4f' % mejor_modelo.score(Xval_scaled, yval))\n",
    "\n",
    "# Visualización\n",
    "plt.title('SVM con kernel gaussiano (Conjunto de datos 3)')\n",
    "plt.margins(x=0, y=0)\n",
    "plt.scatter(X_scaled[:,0], X_scaled[:,1], c=y, s=10, cmap='prism', label='Conjunto de entrenamiento')\n",
    "plt.scatter(Xval_scaled[:,0], Xval_scaled[:,1], c=yval, marker='x', s=20, cmap='prism', label='Conjunto de validacion')\n",
    "plot_svc_decision_function(mejor_modelo, plot_support=False, levels=[0], linestyles=['-']) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de hiperparámetros para SVM con GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probar la funcionalidad de GridSearchCV de la librería \"sklearn\" para identificar los mejores hiperparámetros para el algoritmo SVM sobre el conjunto de entrenamiento \"train\". Luego, analice el resultado en el conjunto de validación \"valid\".\n",
    "<br>http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "<br>http://scikit-learn.org/stable/modules/grid_search.html#multimetric-grid-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C':np.logspace(-2,2,9), 'gamma':np.logspace(-4,4,9)}\n",
    "\n",
    "model = SVC()\n",
    "gridsearchcv = GridSearchCV(model, param_grid, cv=5)\n",
    "\n",
    "gridsearchcv.fit(X_scaled, y)\n",
    "\n",
    "print(gridsearchcv.best_params_)\n",
    "print(gridsearchcv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_model = SVC(kernel='rbf', C=10, gamma=1)\n",
    "val_model.fit(X_scaled, y)\n",
    "\n",
    "validation_score = val_model.score(Xval_scaled, yval)\n",
    "print(validation_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
